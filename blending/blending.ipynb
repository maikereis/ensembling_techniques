{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statistics as stts\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/data_cleaned.csv')\n",
    "\n",
    "X, y = data.drop('Survived', axis=1), data.pop('Survived')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Creade models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = DecisionTreeClassifier()\n",
    "KNN = KNeighborsClassifier()\n",
    "LR = LogisticRegression(solver='lbfgs', max_iter=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Evaluate each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.770949720670391, 0.6927374301675978, 0.7988826815642458)"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DT.fit(X_train, y_train)\n",
    "KNN.fit(X_train, y_train)\n",
    "LR.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "DT.score(X_test, y_test), KNN.score(X_test, y_test) , LR.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train models and create new datasets using their predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 First approach: feeding the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predictions_holdout(model, X_train, y_train, X_holdout, X_test):\n",
    "    #train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    model_name = model.__class__.__name__\n",
    "    model_name = \"\".join(c for c in model_name if c.isupper()) \n",
    "\n",
    "    #storing predictions for train and test\n",
    "    pred_train=model.predict(X_holdout)\n",
    "    pred_train = pd.DataFrame(pred_train, index = X_holdout.index, columns=[model_name])\n",
    "    pred_test=model.predict(X_test)\n",
    "    pred_test = pd.DataFrame(pred_test, index = X_test.index, columns=[model_name])\n",
    "\n",
    "    return pred_train, pred_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = DecisionTreeClassifier()\n",
    "KNN = KNeighborsClassifier()\n",
    "LR = LogisticRegression(solver='liblinear', max_iter=1000)\n",
    "\n",
    "X_train, X_holdout, y_train, y_holdout = train_test_split(X_train, y_train, test_size=0.3)\n",
    "\n",
    "\n",
    "M1_train, M1_test = model_predictions_holdout(DT, X_train, y_train, X_holdout, X_test)\n",
    "M2_train, M2_test = model_predictions_holdout(KNN, X_train, y_train, X_holdout, X_test)\n",
    "M3_train, M3_test = model_predictions_holdout(LR, X_train, y_train, X_holdout, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Create the base models predictions dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_meta = pd.concat([X_holdout, M1_train, M2_train, M3_train],axis=1)\n",
    "X_test_meta = pd.concat([X_test, M1_test, M2_test, M3_test],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eng_r\\Envs\\ensembletech\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.776536312849162"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stacker Model\n",
    "meta_model = LogisticRegression()\n",
    "meta_model.fit(X_train_meta, y_holdout)\n",
    "meta_model.score(X_test_meta,y_test)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "28a5f5bc7277c3ff611db003fc39c6e486462a4e0b6ad71d09a0177baf05ed21"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit ('ensembletech': virtualenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
